{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2bad73",
   "metadata": {},
   "source": [
    "COLLECTE DONNEES ENTREPRISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad196ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bouton cliqué avec succès.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Configuration du WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.trustpilot.com/categories/atm\"\n",
    "driver.get(url)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "time.sleep(2)\n",
    "\n",
    "# Fermer le bouton cookie\n",
    "try:\n",
    "    button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'onetrust-close-btn-handler')))\n",
    "    button.click()\n",
    "    print(\"Bouton cliqué avec succès.\")\n",
    "except Exception as e:\n",
    "    print(\"Impossible de cliquer sur le bouton :\", e)\n",
    "\n",
    "# Collecter les informations sur les entreprises\n",
    "entreprise_elements = driver.find_elements(By.CLASS_NAME, 'styles_businessUnitMain__PuwB7')\n",
    "\n",
    "informations_entreprises = []\n",
    "\n",
    "for entreprise in entreprise_elements:\n",
    "    try:\n",
    "        nom_entreprise = entreprise.find_element(By.CSS_SELECTOR, 'p.styles_displayName__GOhL2').text\n",
    "    except NoSuchElementException:\n",
    "        nom_entreprise = 'NA'\n",
    "        \n",
    "    try:\n",
    "        trust_score_element = entreprise.find_element(By.CSS_SELECTOR, 'span.typography_body-m__xgxZ_')\n",
    "        trust_score = trust_score_element.text.split()[-1]\n",
    "    except NoSuchElementException:\n",
    "        trust_score = 'NA'\n",
    "        \n",
    "    try:\n",
    "        reviews = int(entreprise.find_element(By.CSS_SELECTOR, 'p.styles_ratingText__yQ5S7').text.split('|')[-1].strip().replace(',', '').split()[0])\n",
    "    except NoSuchElementException:\n",
    "        reviews = 'NA'\n",
    "        \n",
    "    try:\n",
    "        emplacement = entreprise.find_element(By.CSS_SELECTOR, 'span.styles_location__ILZb0').text\n",
    "    except NoSuchElementException:\n",
    "        emplacement = 'NA'\n",
    "\n",
    "    if reviews == 'NA':\n",
    "        trust_score = 'NA'\n",
    "\n",
    "    informations_entreprises.append({\n",
    "        'Nom': nom_entreprise,\n",
    "        'TrustScore': trust_score,\n",
    "        'Reviews': reviews,\n",
    "        'Emplacement': emplacement,\n",
    "    })\n",
    "\n",
    "# Créer un DataFrame avec les informations des entreprises\n",
    "df_entreprises = pd.DataFrame(informations_entreprises)\n",
    "\n",
    "# Ajouter des informations supplémentaires\n",
    "div_elements = driver.find_elements(By.XPATH, '//div[@class=\"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_wrapper__2JOo2\"]')\n",
    "result_list = []\n",
    "for div in div_elements:\n",
    "    elements = div.find_element(By.CLASS_NAME, 'styles_footer__DoJVj')\n",
    "    elements_2 = elements.find_element(By.CLASS_NAME, 'styles_wrapper___E6__')\n",
    "    span_elements = elements_2.find_elements(By.TAG_NAME, 'span')\n",
    "    concatenated_text = '' \n",
    "    for span in span_elements:\n",
    "        concatenated_text += span.text \n",
    "\n",
    "    result_list.append(concatenated_text)\n",
    "\n",
    "df_new_column = pd.DataFrame(result_list, columns=['infos'])\n",
    "df_entreprises = df_entreprises.assign(infos=df_new_column['infos'])\n",
    "\n",
    "# Extraire des informations supplémentaires et les ajouter au DataFrame\n",
    "df_entreprises['review'] = df_entreprises['Reviews'].apply(lambda x: int(str(x).replace(',', '')) if x != 'NA' else 0)\n",
    "df_entreprises['town'] = df_entreprises['Emplacement'].apply(lambda x: str(x).split(',')[0])\n",
    "df_entreprises['country'] = df_entreprises['Emplacement'].apply(lambda x: str(x).split(',')[-1])\n",
    "df_entreprises['institution_type'] = df_entreprises['infos'].apply(lambda x: str(x).split('·')[0])\n",
    "df_entreprises['five_star_%'] = None  # Placeholder for the next part\n",
    "df_entreprises['company_name'] = df_entreprises['Nom']\n",
    "df_entreprises['trust_score'] = df_entreprises['TrustScore']\n",
    "\n",
    "df_entreprises = df_entreprises.drop(columns=['Nom', 'TrustScore', 'Reviews', 'Emplacement', 'infos'])\n",
    "\n",
    "# Récupérer les liens des entreprises\n",
    "elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.paper_paper__1PY90.paper_outline__lwsUX.card_card__lQWDv.card_noPadding__D8PcU.styles_wrapper__2JOo2'))\n",
    ")\n",
    "liens = []\n",
    "\n",
    "for element in elements:\n",
    "    link = element.find_element(By.TAG_NAME, 'a')\n",
    "    href = link.get_attribute('href')\n",
    "    liens.append(href)\n",
    "\n",
    "# Collecter le score 5 étoiles pour chaque entreprise\n",
    "scores_5_etoiles = []\n",
    "\n",
    "for href in liens:\n",
    "    driver.execute_script(\"window.open('{}', '_blank');\".format(href))\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    \n",
    "    try:\n",
    "        score_5_etoile = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/main/div/div[4]/section/div[2]/div[2]/label[1]/p[2]').text\n",
    "    except NoSuchElementException:\n",
    "        score_5_etoile = 'NA'\n",
    "    \n",
    "    scores_5_etoiles.append(score_5_etoile)\n",
    "    \n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# Ajouter les scores 5 étoiles au DataFrame\n",
    "df_entreprises['five_star_%'] = scores_5_etoiles\n",
    "\n",
    "# Sauvegarder le DataFrame\n",
    "df_entreprises.to_csv(r'C:\\Users\\MSI KATANA B13V\\Desktop\\PARCOURS DE\\Projet Fil Rouge\\de_satisfaction_client\\data\\informations_entreprises.csv', index=False)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7c16d",
   "metadata": {},
   "source": [
    "COLLECTE DONNEES COMMENTAIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95cb66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bouton cliqué avec succès.\n",
      "Les données des commentaires ont été enregistrées dans le fichier commentaires.json.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Recharger les informations des entreprises\n",
    "df_entreprises = pd.read_csv('informations_entreprises.csv')\n",
    "\n",
    "# Configuration du WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.trustpilot.com/categories/atm\")\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Fermer le bouton cookie\n",
    "try:\n",
    "    button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'onetrust-close-btn-handler')))\n",
    "    button.click()\n",
    "    print(\"Bouton cliqué avec succès.\")\n",
    "except Exception as e:\n",
    "    print(\"Impossible de cliquer sur le bouton :\", e)\n",
    "\n",
    "# Récupérer les liens des entreprises\n",
    "elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.paper_paper__1PY90.paper_outline__lwsUX.card_card__lQWDv.card_noPadding__D8PcU.styles_wrapper__2JOo2'))\n",
    ")\n",
    "liens = []\n",
    "\n",
    "for element in elements:\n",
    "    link = element.find_element(By.TAG_NAME, 'a')\n",
    "    href = link.get_attribute('href')\n",
    "    liens.append(href)\n",
    "\n",
    "# Collecter les commentaires pour chaque entreprise\n",
    "commentaires_par_agence = []\n",
    "\n",
    "for href in liens:\n",
    "    driver.execute_script(\"window.open('{}', '_blank');\".format(href))\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "    titre = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div/main/div/div[3]/div[2]/div/div/div/section/div[1]/div[2]/h1/span[1]'))\n",
    "    )\n",
    "    titre_text = titre.text\n",
    "\n",
    "    comments = driver.find_elements(By.CSS_SELECTOR, 'article.styles_reviewCard__hcAvl')\n",
    "    i = 0\n",
    "\n",
    "    for comment in comments:\n",
    "        try:\n",
    "            user_name = comment.find_element(By.CSS_SELECTOR, '.typography_heading-xxs__K8PzI').text\n",
    "        except NoSuchElementException:\n",
    "            user_name = 'NA' \n",
    "        try:\n",
    "            location_element = driver.find_elements(By.CSS_SELECTOR, '[data-consumer-country-typography] > span')\n",
    "            location_element = location_element[i]\n",
    "            user_location = location_element.text\n",
    "        except NoSuchElementException:\n",
    "            user_location = 'NA' \n",
    "        try:\n",
    "            review_content_element = driver.find_element(By.CSS_SELECTOR, 'div[data-review-content]')\n",
    "            review_content = review_content_element.text\n",
    "        except NoSuchElementException:\n",
    "            review_content = 'NA' \n",
    "        try:\n",
    "            title = comment.find_element(By.CSS_SELECTOR, '.typography_heading-s__f7029').text\n",
    "        except NoSuchElementException:\n",
    "            title = 'NA'          \n",
    "        try:\n",
    "            review_text = comment.find_element(By.CSS_SELECTOR, '.typography_body-l__KUYFJ').text\n",
    "        except NoSuchElementException:\n",
    "            review_text = 'NA'          \n",
    "        try:\n",
    "            review_count_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '.styles_consumerExtraDetails__fxS4S > span.typography_body-m__xgxZ_'))\n",
    "            )\n",
    "            review_count = int(review_count_element.text.split()[0].replace(',', ''))\n",
    "        except NoSuchElementException:\n",
    "            review_count = 'NA'      \n",
    "             \n",
    "        try:\n",
    "            date_of_experience_element = comment.find_element(By.CSS_SELECTOR, 'p[data-service-review-date-of-experience-typography]')\n",
    "            date_of_experience = date_of_experience_element.text.replace('Date of experience: ', '').strip()\n",
    "        except NoSuchElementException:\n",
    "            date_of_experience = 'NA'\n",
    "            \n",
    "        try:\n",
    "            reply_element = comment.find_element(By.CSS_SELECTOR, '.paper_paper__1PY90')\n",
    "            reply_text = reply_element.find_element(By.CSS_SELECTOR, '.styles_message__shHhX').text\n",
    "            reply_date_element = reply_element.find_element(By.CSS_SELECTOR, '.styles_replyDate__Iem0_')\n",
    "            reply_date = reply_date_element.get_attribute('title')\n",
    "            \n",
    "            comment_data = {\n",
    "                'company_name': titre_text,\n",
    "                'User': user_name,\n",
    "                'localisation': user_location,\n",
    "                'Titre': title,\n",
    "                'commentaire': review_text,\n",
    "                'nombre_reviews': review_count,\n",
    "                'date_experience': date_of_experience,\n",
    "                'reply': {\n",
    "                    'reply_text': reply_text,\n",
    "                    'reply_date': reply_date\n",
    "                }\n",
    "            }\n",
    "        except NoSuchElementException:\n",
    "            comment_data = {\n",
    "                'company_name': titre_text,\n",
    "                'User': user_name,\n",
    "                'localisation': user_location,\n",
    "                'Titre': title,\n",
    "                'commentaire': review_text,\n",
    "                'nombre_reviews': review_count,\n",
    "                'date_experience': date_of_experience,\n",
    "                'reply': None\n",
    "            }\n",
    "\n",
    "        # Ajouter les données du commentaire (avec ou sans réponse) à la liste des commentaires de l'agence\n",
    "        commentaires_par_agence.append(comment_data)\n",
    "        i += 1\n",
    "\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "\n",
    "# Enregistrement des données des commentaires dans un fichier JSON\n",
    "with open(r'C:\\Users\\MSI KATANA B13V\\Desktop\\PARCOURS DE\\Projet Fil Rouge\\de_satisfaction_client\\data\\commentaires.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(commentaires_par_agence, f, ensure_ascii=False, indent=4)\n",
    "print(\"Les données des commentaires ont été enregistrées dans le fichier commentaires.json.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
